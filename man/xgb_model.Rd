% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/xgb.R
\name{xgb_model}
\alias{xgb_model}
\title{Train a Gradient Boosting Model using XGBoost}
\usage{
xgb_model(train_vectorized, Y, test_vectorized)
}
\arguments{
\item{train_vectorized}{The training feature matrix (e.g., a `dfm` from quanteda).}

\item{Y}{The response variable for the training set. Should be a factor.}

\item{test_vectorized}{The test feature matrix, which must have the same
features as `train_vectorized`.}
}
\value{
A list containing two elements:
  \item{pred}{A vector of class predictions for the test set.}
  \item{model}{The final, trained `xgb.Booster` model object.}
}
\description{
This function trains a model using the xgboost package. It is highly
efficient and natively supports sparse matrices, making it ideal for text data.
It automatically handles both binary and multi-class classification problems.
}
