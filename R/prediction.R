#' Predict Sentiment on New Data Using a Saved Pipeline Artifact
#'
#' This is a generic prediction function that handles different model types
#' and ensures consistent preprocessing and vectorization for new, unseen text.
#'
#' @param pipeline_object A list object returned by the main `pipeline()` function.
#'   It must contain the trained model, DFM template, preprocessing function,
#'   and n-gram settings.
#' @param new_raw_text_vector A character vector of new, raw documents to be scored.
#'
#' @return A vector of class predictions for the new data.
#'
#' @importFrom stats predict
#' @importFrom xgboost xgb.DMatrix
#'
#' @export
prediction <- function(pipeline_object,
                       df,
                       text_column) {
  
  # --- 1. Extract the necessary artifacts from the pipeline object ---
  final_model <- pipeline_object$trained_model
  dfm_template <- pipeline_object$dfm_template
  class_levels <- pipeline_object$class_levels #for XGBoost since it does only numeric for Y
  
  # --- 2. Preprocess and vectorize the new data ---
  cat("--- Preparing new data for prediction ---\n")
  cat("  - Applying Bag-of-Words transformation and matching features...\n")
  new_dfm <- BOW_test(df[[text_column]], dfm_template, pipeline_object$ngram_size_used)
  
  # --- 3. Conditional Prediction based on Model Class ---
  cat("--- Making Predictions ---\n")
  
  # Initialize a variable to hold the final predictions
  final_predictions <- NULL
  
  # Check the class of the model object
  if ("cv.glmnet" %in% class(final_model)) {
    
    cat("  - Detected a glmnet model. Using predict.cv.glmnet().\n")
    final_predictions <- predict(final_model, 
                                 newx = new_dfm, 
                                 s = "lambda.min", 
                                 type = "class")
    # glmnet returns a matrix, so we extract the first column
    final_predictions <- final_predictions[, 1]
    
  } else if ("ranger" %in% class(final_model)) {
    
    cat("  - Detected a ranger model. Using predict.train().\n")
    # Models like ranger/randomForest need a dense matrix
    new_dense_matrix <- as.matrix(new_dfm)
    
    cat("Step 4: Correcting column names for ranger model...\n")
    model_colnames <- final_model$forest$independent.variable.names
    colnames(new_dense_matrix) <- model_colnames
    
    prediction_obj <- predict(final_model, data = new_dense_matrix)
    final_predictions <- prediction_obj$predictions
    
    
  } else if ("xgb.Booster" %in% class(final_model)) {
    cat("  - Detected an xgboost model. Predicting...\n") 
    # 1. Convert the new DFM into the required xgb.DMatrix format
    new_dmatrix <- xgb.DMatrix(data = new_dfm)
    
    # 2. Predict probabilities. reshape=TRUE creates a matrix for multi-class.
    pred_probabilities <- predict(final_model, newdata = new_dmatrix, reshape = TRUE)
    
    # 3. Convert probabilities to final class labels
    if (is.vector(pred_probabilities)) { # Binary case
      # If the output is a single vector of probabilities for the positive class
      pred_numeric <- ifelse(pred_probabilities > 0.5, 1, 0)
    } else { # Multi-class case
      # If the output is a matrix, find the column with the highest probability for each row
      pred_numeric <- max.col(pred_probabilities) - 1 # Get 0-indexed class number
    }
    
    # 4. Convert numeric class (0, 1, 2...) back to the original factor levels
    final_predictions <- factor(pred_numeric, 
                                levels = 0:(length(class_levels) - 1), 
                                labels = class_levels)
  } else {
    stop(paste("Unsupported model type:", class(final_model)[1]))
  }
     
  cat("--- Predictions Complete ---\n")
  return(final_predictions)
}

